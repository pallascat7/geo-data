---
title: "Spatial_distribution_Modelling"
author: "Nimirta Kaur"
date: "2023-03-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Species distribution modelling
```{r Packages}
#install.packages('dismo')  ##for my installation, get a question on install for 'terra' package and need to click "no" instead of "yes"
#install.packages('rworldmap')
#install.packages('sf')
#install.packages('geodata')

library(dismo)
library(rworldmap)
library(sf)
library(geodata)
```

```{r creating a simple world map}
	wrld_simpl<-getMap(resolution = "coarse")
```
```{r extracting data for wanted spacies}
species.gbif <- gbif("coffea","arabica", geo=TRUE)
species.coords<-cbind(species.gbif$lon,species.gbif$lat)
species.coords<-na.omit(species.coords)
species.coords<-data.frame(species.coords)
colnames(species.coords)<-c("lon","lat")
```
```{r plotting distrubution of coffee}
	plot(wrld_simpl, xlim=range(species.coords$lon), ylim=range(species.coords$lat), axes=TRUE, col="light yellow")
	points(species.coords, col='red', cex=0.75)
```
```{r triming coordinates function }
	trim.coords<-function (x,latmin,latmax,lonmin,lonmax) {
			if (sum(x$lon < lonmin)>0) {
			tmp<-which(x$lon < lonmin)
			x<-x[-tmp,]}
				if (sum(x$lon > lonmax)>0) {
				tmp<-which(x$lon > lonmax)
				x<-x[-tmp,]}
					if (sum(x$lat < latmin)>0) {
					tmp<-which(x$lat < latmin)
					x<-x[-tmp,]}
						if (sum(x$lat > latmax)>0) {
						tmp<-which(x$lat > latmax)
						x<-x[-tmp,]}
				return(x) }
```

```{r the trim}
species.coords.trim<-trim.coords(species.coords,latmin=-40,latmax=40,lonmin=-20,lonmax=55)
	
##plot world map again now using the trimmed data
	plot(wrld_simpl, xlim=range(species.coords.trim$lon), ylim=range(species.coords.trim$lat), axes=TRUE, col="light yellow")
##add points for this species
	points(species.coords.trim, col='red', cex=0.75)
		species.coords<-species.coords.trim
```
```{r coffee growns in the sea??}
URL <- "https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/110m/physical/ne_110m_ocean.zip"
	fil <- basename(URL)
	if (!file.exists(fil)) download.file(URL, fil)
	fils <- unzip(fil)
	##read in the downloaded file as a shape file
	oceans <- read_sf(grep("shp$", fils, value=TRUE))
	##convert our locality points into equivalent format
	species.coords<- st_as_sf(species.coords,coords=c("lon","lat"))
	st_crs(species.coords) <- st_crs(oceans)
	sf_use_s2(FALSE)
	##find where out points intersect with the ocean
	tmp<-sapply(st_intersects(species.coords,oceans), function(z) if (length(z)==0) NA_integer_ else z[1])
	##remove points that intersect with the ocean and convert back to table of coordinates
	if (sum(!is.na(tmp))>0) {
	species.coords<-data.frame(st_coordinates(species.coords[is.na(tmp),]))} else {
		species.coords<-data.frame(st_coordinates(species.coords))}
	colnames(species.coords)<-c("lon","lat")
	
##now plot again to check - looks OK
	plot(wrld_simpl, xlim=range(species.coords$lon), ylim=range(species.coords$lat), axes=TRUE, col="light yellow")
	points(species.coords, col='red', cex=0.75)
```

## Extract climatic values for the localities occupied by the species
```{r}
bio.data<-worldclim_global(var="bio",res=10,path=getwd())
	names(bio.data)<-paste0("bio",1:19)
#Plotting bioclimatic data for Annual Mean Temperature and mean diurnal range}
plot(bio.data,1) # bio1 is Annual Mean Temperature
plot(bio.data,2) # bio2 is mean diurnal range
#https://www.worldclim.org/data/bioclim.html
```
```{r bioclimatic data for the focal localities in Africa where your species is found}
bio.values <- extract(bio.data, species.coords)[,-1] 
rownames(bio.values)<-rownames(species.coords)
plot(bio.values[,1],bio.values[,2])
```
```{r bioclimatic variables 1 - 5}
pairs(bio.values[,1:5])

#BIO1 = Annual Mean Temperature
#BIO2 = Mean Diurnal Range (Mean of monthly (max temp - min temp))
#BIO3 = Isothermality (BIO2/BIO7) (×100)
#BIO4 = Temperature Seasonality (standard deviation ×100)
#BIO5 = Max Temperature of Warmest Month
```
```{r}
species.data<-cbind(species.coords,bio.values)
species.data<-na.omit(species.data)
write.csv(species.data,file="species.data.csv")
```
```{r}
rbind(mean=colMeans(species.data),
	min=apply(species.data, 2, min),
	max=apply(species.data, 2, max))
```

We will run a linear model - like a regression, but where Y is presence/absence and X variables are values of the bioclimatic variable. The problem is that we don't have absence data, i.e. that someone visited and said  the species is definitely not present. So instead we create pseudo absence data using background points with no presence recorded from the same general region.I'll refer to these as background points
```{r Make random background points for your region}
#This bit makes a raster from the world map, which is a shaded region
ext <- extent(wrld_simpl)
xy <- abs(apply(as.matrix(bbox(ext)), 1, diff))
n <- 5
r <- raster(ext, ncol=xy[1]*n, nrow=xy[2]*n)
mask <-rasterize(wrld_simpl, r)

plot(mask, axes = TRUE, col = "lightgrey",
     xlim = c(-15, 50),
     ylim = c(-40,22)); box()
points(species.coords,col = "#ff0660", pch = 20, cex = 1)

e <- extent(-15, 50, -40,22)
plot(e, add=TRUE, col='black')

bg <- randomPoints(mask, 500, ext=e,extf=1)
points(bg,col="black", pch=20)
colnames(bg)<-c("lon","lat")

#the black points are the background points with no recorded presence in GBIF
#the red points are the observed localities
bio.data<-crop(bio.data,e)
```

```{r}
#combine the presence data and the background data in one table
train <- rbind(species.coords, bg)

#and make a vector record 1=presence, 0=background
pb_train <- c(rep(1, nrow(species.coords)), rep(0, nrow(bg))) 

#extract bioclimatic data for these points
envtrain <- extract(bio.data, train)
envtrain <- data.frame(cbind(pa=pb_train, envtrain) )
##and for each set separately
testpres <- data.frame( extract(bio.data, species.coords) )
testbackg <- data.frame( extract(bio.data, bg))

```

```{r}
# pa = pb_train (1 = presence, 0=background)
 gm1 <- glm(pa ~ bio1 + bio2 + bio3 + bio4 + bio5,
     family = binomial(link = "logit"), data=envtrain)
#can add 6,7,8,9,10)
     
 ##look at a summary of the results
summary(gm1)
```

bio1, bio2, bio4 and bio5

#Predict species distribution from the model and plot it
```{r}
	pg <- predict(bio.data, gm1, ext=e,type="response")
	pg<-crop(pg,e)
	
	#representing the probability of occurrence from our linear model, for or area of extent e
plot(pg, main='GLM probability of occurrence')
plot(wrld_simpl, add=TRUE, border='dark grey') 
points(species.coords,col = "black", pch = 4, cex = 0.5)

## evaluate how well the model predicts presence/absence at each point
ge <- evaluate(testpres, testbackg, gm1)
ge
#use this evaluation to pick a threshold probability for defining presence/absence
#using the model that gives the most accurate match to observed presence/absence
tr <- threshold(ge, 'prevalence')
plot(pg > tr, main='presence/absence')
plot(wrld_simpl, add=TRUE, border='dark grey') 
points(species.coords,col = "red", pch = 4, cex = 0.5)
```
Area Under the Curve: AUC, and correlation coefficient between observed and predicted.
Higher values of both metrics = better match between model predictions and observed  presence/absences.
62.5 (what is our thrshiold )

#use this evaluation to pick a threshold probability for defining presence/absence
using the model that gives the most accurate match to observed presence/absence

```{r}
gm2 <- glm(pa ~ bio6 + bio7 + bio8 + bio9 + bio10,family = binomial(link = "logit"), data=envtrain)
summary(gm2)

#You can compare two models, even with different predictor variables, using the Akaike Information Criterion
AIC(gm1,gm2)
#A lower score = better model, difference of 2 units is regarded as 'significantly' better, less than 2 means not really that different. You could try running a set of different models with different explanatory variables to find your best model. Look at the summary of the two models - for me, gm2 had several variables that were not significant in the model, so could be removed successively (starting with least significant)  and check subsequent models using AIC to see whether simpler model (fewer variables) is 'significantly' better.

#therefore: gm1 is a better predictor
```
sign doff between presnce and absence 
bio10 
gm1 is a better predictor


```{r}
evaluate(testpres, testbackg, gm2)
evaluate(testpres, testbackg, gm1)
```
61.7 vs 62.5


#PREDICT FUTURE SPECIES RANGES
```{r}
future.bio.data<-cmip6_world(model="CanESM5",var="bio",ssp="245",res=10,time="2061-2080",path=getwd())
names(future.bio.data)<-names(bio.data)
future.bio.data<-crop(future.bio.data,e)
```
```{r}
par(mfrow=c(1,2))

plot(pg, main='A) GLM present')
	plot(wrld_simpl, add=TRUE, border='dark grey') 
	points(species.coords,col = "black", pch = 4, cex = 0.5)
	
pg.future <- predict(future.bio.data, gm1, ext=e,type="response")

	pg.future<-crop(pg.future,e)
	plot(pg.future, main="B) GLM, 2060-2081")
	plot(wrld_simpl, add=TRUE, border='dark grey') 
	points(species.coords,col = "black", pch = 4, cex = 0.5)
```
We can extract some numbers about how the range will change. For example, among all of the localities and background points, how many is it predicted to be in presently?
```{r}
predict.localities.now <- extract(pg>=tr, species.coords)[,-1]
sum(predict.localities.now)


predict.localities.future <- extract(pg.future>=tr, species.coords)[,-1]
#nas in predict.localities.future
predict.localities.future1 <- na.omit(predict.localities.future)
sum(predict.localities.future1)

sum((predict.localities.now==0)&(predict.localities.future1==1)) # in the future but not in the past
sum((predict.localities.now==1)&(predict.localities.future1==0)) # 57
```

```{r}
change.bio.data<-future.bio.data-bio.data

par(mfrow=c(1,3))
plot(bio.data[[1]],ext=e,main="Present")
plot(future.bio.data[[1]],ext=e,main="Future")
plot(change.bio.data[[1]],ext=e,main="Change")

```


